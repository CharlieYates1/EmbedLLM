{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd654f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf3f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charlie\\anaconda3\\envs\\ai_assistant\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "W1225 18:41:58.775000 26716 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceiver latent dimension: 512\n",
      "Perceiver number of latents: 784\n",
      "Created input projection: 2560 -> 704\n",
      "Gradient checkpointing enabled\n",
      "Cross-attention inserted at layer 8\n"
     ]
    }
   ],
   "source": [
    "from QwenWithPerceiverCrossAttn import QwenWithPerceiverCrossAttn\n",
    "model = QwenWithPerceiverCrossAttn().to(device).to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a670636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "qwen_model_name = \"Bossologist/Qwen3-4B-Instruct-2507_general_ft_merged\"\n",
    "tokenizer_path = qwen_model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcc24df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11526,   498,  3730,  2494,  2937], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"Are you doing something later\"\n",
    "encoded = tokenizer(\n",
    "    input,\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "# input_ids must be Long (int64), not float16\n",
    "input_ids = encoded[\"input_ids\"].to(device).long()\n",
    "attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77be58a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2']\n"
     ]
    }
   ],
   "source": [
    "output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "# Convert logits to predicted token IDs and decode to text\n",
    "logits = output[0][:, -1, :]\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "pred_text = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "print(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8673f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 77,642,369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2567191041"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params:,}\")\n",
    "sum([p.numel() for p in model.qwen_model.model.model.parameters() if p.requires_grad])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
