{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd654f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26311378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charlie\\anaconda3\\envs\\ai_assistant\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "W1225 08:22:58.955000 38644 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "qwen_model_name = \"Bossologist/Qwen3-4B-Instruct-2507_general_ft_merged\"\n",
    "\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    qwen_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bf880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created input projection: 2560 -> 704\n"
     ]
    }
   ],
   "source": [
    "from perceiver_module import PerceiverIOModule, CrossAttentionCompressor\n",
    "\n",
    "latent_dim = 512\n",
    "\n",
    "perceiver_module = PerceiverIOModule(\n",
    "    input_dim=qwen_model.config.hidden_size,\n",
    ").to(device)\n",
    "\n",
    "compressor = CrossAttentionCompressor(\n",
    "    latent_dim=latent_dim,\n",
    "    num_heads=8,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a670636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_path = qwen_model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abcc24df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"Hello there my friend, how are you?\"\n",
    "encoded = tokenizer(\n",
    "    input,\n",
    "    max_length=2048,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "input_ids = encoded[\"input_ids\"].to(device)\n",
    "attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a698e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0151, -0.0030, -0.0091,  ..., -0.0067,  0.0154,  0.0013],\n",
       "         [-0.0060,  0.0098,  0.0160,  ...,  0.0072,  0.0408,  0.0229],\n",
       "         [-0.0277,  0.0269,  0.0002,  ...,  0.0012,  0.0155, -0.0036],\n",
       "         ...,\n",
       "         [-0.0181,  0.0013, -0.0035,  ..., -0.0305,  0.0153,  0.0032],\n",
       "         [-0.0208,  0.0033,  0.0082,  ...,  0.0126,  0.0127,  0.0305],\n",
       "         [-0.0168, -0.0410,  0.0051,  ..., -0.0031, -0.0148,  0.0481]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer = qwen_model.get_input_embeddings()\n",
    "turn_embeddings = embed_layer(input_ids).to(device)\n",
    "turn_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77be58a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = perceiver_module(turn_embeddings)\n",
    "outputs[0][0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
